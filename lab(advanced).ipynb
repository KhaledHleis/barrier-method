{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_variance(w, C):\n",
    "    return np.dot(w.T, np.dot(C, w))\n",
    "\n",
    "def gradient(C, w):\n",
    "    return 2 * np.dot(C, w)\n",
    "\n",
    "def projection_onto_simplex(w):\n",
    "    \"\"\"Project vector w onto the simplex defined by the constraints w >= 0 and sum(w) = 1.\"\"\"\n",
    "    if np.sum(w) > 1:\n",
    "        w = w / np.sum(w)  # Scale if exceeding 1\n",
    "    return np.maximum(w, 0)  # Ensure non-negativity\n",
    "\n",
    "def barrier_method(C, initial_w, mu_start=10, mu_end=1e-4, rho=0.5, epsilon=1e-8, max_iter=100):\n",
    "    n = len(initial_w)\n",
    "    w = initial_w.copy()\n",
    "    mu = mu_start\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "        w_proj = projection_onto_simplex(w)  # Ensure non-negative weights and sum to 1\n",
    "        \n",
    "     \n",
    "        inv_w_proj = 1 / (w_proj.flatten() + 1e-10)  # Inverse for log barrier with small epsilon\n",
    "    \n",
    "        if len(w_proj) != C.shape[0]:\n",
    "            raise ValueError(\"Weight vector length must match the covariance matrix dimensions.\")\n",
    "        \n",
    "        gradient_value = gradient(C, w_proj.flatten()) - mu * np.sum(inv_w_proj) * np.ones(n)\n",
    "\n",
    "        step_size = 1.0\n",
    "        while True:\n",
    "            new_w = w - step_size * gradient_value\n",
    "            new_w_proj = projection_onto_simplex(new_w)  # Project to ensure feasible weights\n",
    "            if np.all(new_w_proj >= 0):  # Ensure non-negative weights\n",
    "                break\n",
    "            step_size *= rho \n",
    "        # Update weights and reduce mu\n",
    "        w = new_w\n",
    "        mu *= 0.5  # Reduce barrier parameter\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(gradient_value) < epsilon:\n",
    "            print(f\"Converged after {iter} iterations.\")\n",
    "            break\n",
    "\n",
    "    return w\n",
    "\n",
    "# Example usage\n",
    "C = np.cov(HSi_train, rowvar=False)  # Ensure rowvar=False if columns are assets\n",
    "\n",
    "\n",
    "print(\"Shape of C:\", C.shape) \n",
    "print(\"Shape of HSi_train:\", HSi_train.shape)  \n",
    "\n",
    "# Initialize weights based on the number of assets\n",
    "num_assets = C.shape[0] \n",
    "w_init = (1 / num_assets) * np.ones(num_assets)\n",
    "\n",
    "\n",
    "w_init /= np.sum(w_init)\n",
    "\n",
    "optimal_weights_adv, w_unconstrained_history = gradient_descent_with_projection(C, w_init, learning_rate=0.01, max_iter=1000)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Optimal Weights: {optimal_weights_adv}\")\n",
    "print(f\"Final Portfolio Variance: {portfolio_variance(optimal_weights_adv, C)}\")\n",
    "\n",
    "# Plotting the results for w_constrained\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(w_constrained, marker='o', label='Constrained Weights (Barrier Method)')\n",
    "plt.title('Constrained Optimal Weights (Barrier Method)')\n",
    "plt.xlabel('Asset Index')\n",
    "plt.ylabel('Weight Value')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
